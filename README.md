# OGRIT

This repository contains the code for the
paper [Verifiable Goal Recognition for Autonomous Driving with Occlusions](https://arxiv.org/abs/2206.14163).

If you find this code useful, please reference in your paper:

```
@misc{brewitt2023ogrit,
   title={Verifiable Goal Recognition for Autonomous Driving with Occlusions},
   author={Cillian Brewitt and Massimiliano Tamborski and Cheng Wang and Stefano V. Albrecht},
   booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
   year={2023}
}
```

## Installation

1) Install IGP2, as specified on https://github.com/uoe-agents/IGP2.
   Note: please install the `ogrit` branch of IGP2. Therefore the suggested sequence of steps is as follows:
    ```
    git clone https://github.com/uoe-agents/IGP2.git
    cd IGP2
    git checkout ogrit
    pip install -e .
    ```

3) Install OGRIT with pip:
    ```
    cd OGRIT
    pip install -e .
    ```

4) Set up the required folders by running:
   ```
    python ogrit/core/base.py
   ```
5) Copy the data from the [inD](https://www.ind-dataset.com/) dataset into `OGRIT/scenarios/data/ind`, and from
   the [rounD](https://www.round-dataset.com/) dataset into `OGRIT/scenarios/data/round`.


6) Extract the occlusions. You can either:
    1) Download the folders `bendplatz_pickle`, `frankenburg_pickle`, `heckstrasse_pickle` and `neuweiler_pickle`
       from the [inDO and rounDO datasets](https://doi.org/10.7488/ds/3498 ). Then, unzip them and copy the files inside
       them in the `OGRIT/occlusions`
       folder.
    2) OR run the following command:
        ```
        python scripts/extract_occlusions.py
        ```


7) Preprocess the data and extract the base and indicator features:
   ```
   python scripts/preprocess_data.py
   ```

   The task above may take hours to complete. If you have access to a SLURM sever, you could use
   the `SLURM_extract_occlusions_example.sh` SBATCH script
   as an example to extract the base and indicator features. You need to create a script for each of the scenarios.
   More instructions are given in the example file mentioned.


7) Train OGRIT and the baseline (G-GRIT). Then calculate the evaluation metrics on the test set:

    ```
    python scripts/train_occlusion_grit.py
    python scripts/train_generalised_decision_trees.py
    python scripts/evaluate_models_from_features.py --models occlusion_grit,generalised_grit,occlusion_baseline
    python scripts/plot_results.py
    ```

8) To train the LSTM baselines, use the following code:

    ```
   # You change the LSTM hyper-parameters, by adding arguments (e.g., --batch_size 32) to the commands below. See the full list of arguments available by running `python baselines/lstm/get_results.py --help`
    python baselines/lstm/get_results.py --train_scenarios rdb1,rdb2,rdb3,rdb4,rdb5,rdb6,rdb7 --test_scenarios neuweiler # Cross-Dataset evaluation
    python baselines/lstm/get_results.py --train_scenarios bendplatz --test_scenarios bendplatz # Train and test on `bendplatz`
   
    python scripts/plot_results.py --models lstm-ogrit_features-25-remove-all --scenarios generalization,bendplatz
    ```

# Occlusion detection

### a) Visualize the occlusions as they are generated by the occlusion detection algorithm

To visualize the occlusions generated by the occlusion detection algorithm, first complete steps 1-3 above and then,
from the `OGRIT/` directory, run the following command:

```

python scripts/extract_occlusions_one_episode.py --scenario heckstrasse --episode_id 0 --debug

```

to visualise all the occlusions for each vehicle in the frame. Otherwise,

By default, the above will give the occlusions for the `bendplatz` scenario, episode `0`.
You can change it by adding the `--scenario` and `--episode_idx` parameters.
For example, to get the occlusions in `frankenburg` episode `3`, you can run the following command:

```

python scripts/extract_occlusions_one_episode.py --scenario frankenburg --episode_idx 3 --debug

```

### b) Visualize the occlusions contained in the [inDO and rounDO datasets](link_see also below)

To visualise the occlusions for one of the episodes contained in the [inDO and rounDO datasets](link_see also below),
follow steps 1-4 of the `OGRIT` section above.

Then, if the episode data is in the JSON format run the following command:

```

python visualise_json_occlusions.py --scenario scenario_name --episode_idx episode_idx --frame_id frame_id

```

Note: you need to change the `scenario_name` and `episode_idx` above according to the episode you want to see the
occlusions for. The `--frame_id` argument can be left out if you want to start from frame `0`.

Otherwise, run the following if the episode data is in pickle format:

```

python visualise_pickle_occlusions.py --scenario scenario_name --episode_idx episode_idx --frame_id frame_id

```

Note: you need to change the `scenario_name` and `episode_idx` above according to the episode you want to see the
occlusions for. The `--frame_id` argument can be left out if you want to start from frame `0`.